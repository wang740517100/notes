---------------------------------- 系统设计 ----------------------------------

高并发方案:
1、高性能
2、高可用
3、高扩展
通用的设计方法维度:
1、纵向扩展: 1)提升单机的硬件性能(内存、cpu核数等); 2)提升单机的软件性能(算法、异步、缓存等);
2、横向扩展: 分层架构、各层进行水平扩展(无状态水平扩容，有状态做分片路由)

❇ 高性能的实践方案
1、集群部署，通过负载均衡减轻单机压力。
2、多级缓存，包括静态数据使用CDN、本地缓存、分布式缓存等，以及对缓存场景中的热点key、缓存穿透、缓存并发、数据一致性等问题的处理。
3、分库分表和索引优化，以及借助搜索引擎解决复杂查询问题。
4、考虑NoSQL数据库的使用，比如HBase、TiDB等，但是团队必须熟悉这些组件，且有较强的运维能力。
5、异步化，将次要流程通过多线程、MQ、甚至延时任务进行异步处理。
6、限流，需要先考虑业务是否允许限流（比如秒杀场景是允许的），包括前端限流、Nginx接入层的限流、服务端的限流。
7、对流量进行削峰填谷，通过MQ承接流量。
8、并发处理，通过多线程将串行逻辑并行化。
9、预计算，比如抢红包场景，可以提前计算好红包金额缓存起来，发红包时直接使用即可。
10、缓存预热，通过异步任务提前预热数据到本地缓存或者分布式缓存中。
11、减少IO次数，比如数据库和缓存的批量读写、RPC的批量接口支持、或者通过冗余数据的方式干掉RPC调用。
12、减少IO时的数据包大小，包括采用轻量级的通信协议、合适的数据结构、去掉接口中的多余字段、减少缓存key的大小、压缩缓存value等。
13、程序逻辑优化，比如将大概率阻断执行流程的判断逻辑前置、For循环的计算逻辑优化，或者采用更高效的算法。
14、各种池化技术的使用和池大小的设置，包括HTTP请求池、线程池（考虑CPU密集型还是IO密集型设置核心参数）、数据库和Redis连接池等。
15、JVM优化，包括新生代和老年代的大小、GC算法的选择等，尽可能减少GC频率和耗时。
16、锁选择，读多写少的场景用乐观锁，或者考虑通过分段锁的方式减少锁冲突。
上述方案无外乎从计算和 IO 两个维度考虑所有可能的优化点，需要有配套的监控系统实时了解当前的性能表现，并支撑你进行性能瓶颈分析，然后再遵循二八原则，抓主要矛盾进行优化。

❇ 高可用的实践方案
1、对等节点的故障转移，Nginx和服务治理框架均支持一个节点失败后访问另一个节点。
2、非对等节点的故障转移，通过心跳检测并实施主备切换（比如redis的哨兵模式或者集群模式、MySQL的主从切换等）。
3、接口层面的超时设置、重试策略和幂等设计。
4、降级处理：保证核心服务，牺牲非核心服务，必要时进行熔断；或者核心链路出问题时，有备选链路。
5、限流处理：对超过系统处理能力的请求直接拒绝或者返回错误码。
6、MQ场景的消息可靠性保证，包括producer端的重试机制、broker侧的持久化、consumer端的ack机制等。
7、灰度发布，能支持按机器维度进行小流量部署，观察系统日志和业务指标，等运行平稳后再推全量。
8、监控报警：全方位的监控体系，包括最基础的CPU、内存、磁盘、网络的监控，以及Web服务器、JVM、数据库、各类中间件的监控和业务指标的监控。
9、灾备演练：类似当前的“混沌工程”，对系统进行一些破坏性手段，观察局部故障是否会引起可用性问题。
高可用的方案主要从冗余、取舍、系统运维3个方向考虑，同时需要有配套的值班机制和故障处理流程，当出现线上问题时，可及时跟进处理。

❇ 高扩展的实践方案
1、合理的分层架构：比如上面谈到的互联网最常见的分层架构，另外还能进一步按照数据访问层、业务逻辑层对微服务做更细粒度的分层（但是需要评估性能，会存在网络多一跳的情况）。
2、存储层的拆分：按照业务维度做垂直拆分、按照数据特征维度进一步做水平拆分（分库分表）。
3、业务层的拆分：最常见的是按照业务维度拆（比如电商场景的商品服务、订单服务等），也可以按照核心接口和非核心接口拆，还可以按照请求源拆（比如To C和To B，APP和H5）。


------------------------------- 安全性 -------------------------------
安全性：
XSS 跨站点脚本攻击
SQL注入攻击
CSRF 跨站点请求伪造

CSRF 和 XSS 的区别
- CSRF：需要用户先登录网站A，获取 cookie。XSS：不需要登录。
- CSRF：是利用网站A本身的漏洞，去请求网站A的api。XSS：是向网站 A 注入 JS代码，
  然后执行 JS 里的代码，篡改网站A的内容


加解密算法:
单向散列加密(加盐): MD5 SHA
对称加密: DES    只有一个秘钥用来加解密
非对称加密: RSA  公钥加密私钥解密 私钥加密公钥解密

---------------------------------- 高并发 ----------------------------------
1)mysql扛一两千
2)redis分担查询压力   几万
3)mq削峰分担写压力    几万
4)分库分表，读写分离
5)es 承担查询压力

6)需要实际的分布式经验

6、分库分表。
分库分表主要为了扛写高并发
分布分表中间件是为了做hash分发

数据库中间件: 1)proxy  2)jar包和服务部署一起
sharding jdbc  升级时所有服务都要升级，耦合太强
mycat          独立运维，需要运维成本

数据库怎么拆分:
垂直拆分: 拆字段    金融订单多表
水平拆分: 拆条数    就是分库分表

根据id hash、 扛压好，扩容男
根据时间 hash  抗压低，扩容易

怎么迁移分库分表：
1、停机迁移数据
2、上线分库分表，将数据双写两个数据源，写一个程序同步老数据源的数据，监听老数据的变化。


---------------------------------- 高可用 ----------------------------------
hystrix：限流、降级、熔断、隔离

限流的算法:
- 固定窗口计数器算法: 无法保证突然激增的流量
- 滑动窗口计数器算法: 粒度细分，60/60
- 漏桶算法: 队列，线程池的等待队列拒绝策略

hystrix:
  command:
    default:
      execution:
        isolation:
          thread:
            timeoutInMillisecond: 10000 # 熔断超时时长：10000ms
压测： postman  Insomnia

---------------------------------- 分布式session ----------------------------------
session和cookie的区别

1)tomcat + redis
tomcat配置文件里配置redisSessionManager的信息
严重依赖于web容器(tomcat), 要是移植web容器怎么办

2)spring session + redis
拦截器

3)自研: 基于es自己搭建

----------------------------------  分布式事务方案 ----------------------------------
1)两阶段提交: spring + jta
微服务不允许连别服务的库，一般都没有使用场景

2)tcc方案:
在catch里面补偿,会增加业务复杂度
一般在强一致性系统使用，一般和钱相关的系统使用。
增加服务订单，取消服务订单

3)本地消息表: mysql消息表
mq或者zk分布式协调

4)可靠消息: 最终一致性
a发消息b，如果b失败a重试

5)最大努力通知方案
记录日志

6)一般都是告警 + 手动补偿


----------------------------------  分布式ID怎么实现 ----------------------------------
UUID
优点：
1）生成足够简单，本地生成无网络消耗，具有唯一性
缺点：
1）无序的字符串，不具备趋势自增特性
2）没有具体的业务含义
3）长度过长16 字节128位，36位长度的字符串，存储以及查询对MySQL的性能消耗较大，MySQL官方明确建议主键要尽量越短越好，
作为数据库主键 UUID 的无序性会导致数据位置频繁变动，严重影响性能。


数据库自增ID：
CREATE DATABASE `SEQ_ID`;
CREATE TABLE SEQID.SEQUENCE_ID (
    id bigint(20) unsigned NOT NULL auto_increment,
    value char(10) NOT NULL default '',
    PRIMARY KEY (id),
) ENGINE=MyISAM;
insert into SEQUENCE_ID(value)  VALUES ('values');
优点：实现简单，ID单调自增，数值类型查询速度快
缺点：DB单点存在宕机风险，无法扛住高并发场景


数据库多主模式：
前边说了单点数据库方式不可取，那对上边的方式做一些高可用优化，换成主从模式集群。害怕一个主节点挂掉没法用，那就做双主模式集群，
也就是两个Mysql实例都能单独的生产自增ID。那这样还会有个问题，两个MySQL实例的自增ID都从1开始，会生成重复的ID怎么办？
解决方案：设置起始值和自增步长
MySQL_1 配置：
set @@auto_increment_offset = 1;     -- 起始值
set @@auto_increment_increment = 2;  -- 步长
MySQL_2 配置：
set @@auto_increment_offset = 2;     -- 起始值
set @@auto_increment_increment = 2;  -- 步长
优点：解决DB单点问题
缺点：不利于后续扩容，而且实际上单个数据库自身压力还是大，依旧无法满足高并发场景。


号段模式：
号段模式是当下分布式ID生成器的主流实现方式之一，号段模式可以理解为从数据库批量的获取自增ID，每次从数据库取出一个号段范围，
例如 (1,1000] 代表1000个ID，具体的业务服务将本号段，生成1~1000的自增ID并加载到内存。表结构如下：
CREATE TABLE id_generator (
  id int(10) NOT NULL,
  max_id bigint(20) NOT NULL COMMENT '当前最大id',
  step int(20) NOT NULL COMMENT '号段的布长',
  biz_type    int(20) NOT NULL COMMENT '业务类型',
  version int(20) NOT NULL COMMENT '版本号',
  PRIMARY KEY (`id`)
)
等这批号段ID用完，再次向数据库申请新号段，对max_id字段做一次update操作，update max_id= max_id + step，update成功则说明新号段获取成功，
新的号段范围是(max_id ,max_id +step]。update id_generator set max_id = #{max_id+step}, version = version + 1 where version = # {version} and biz_type = XXX
由于多业务端可能同时操作，所以采用版本号version乐观锁方式更新，这种分布式ID生成方式不强依赖于数据库，不会频繁的访问数据库，对数据库的压力小很多。


Redis实现：
Redis也同样可以实现，原理就是利用redis的 incr命令实现ID的原子性自增。
127.0.0.1:6379> set seq_id 1     // 初始化自增ID为1
OK
127.0.0.1:6379> incr seq_id      // 增加1，并返回递增后的数值
(integer) 2
用redis实现需要注意一点，要考虑到redis持久化的问题。redis有两种持久化方式RDB和AOF

雪花算法（SnowFlake）：
雪花算法（Snowflake）是twitter公司内部分布式项目采用的ID生成算法，开源后广受国内大厂的好评，在该算法影响下各大公司相继开发出各具特色的分布式生成器。
Snowflake生成的是Long类型的ID，一个Long类型占8个字节，每个字节占8比特，也就是说一个Long类型占64个比特。
Snowflake ID组成结构：正数位（占1比特）+ 时间戳（占41比特）+ 机器ID（占5比特）+ 数据中心（占5比特）+ 自增值（占12比特），总共64比特组成的一个Long类型。
第一个bit位（1bit）：Java中long的最高位是符号位代表正负，正数是0，负数是1，一般生成ID都为正数，所以默认为0。
时间戳部分（41bit）：毫秒级的时间，不建议存当前时间戳，而是用（当前时间戳 - 固定开始时间戳）的差值，可以使产生的ID从更小的值开始；41位的时间戳可以使用69年，
(1L << 41) / (1000L * 60 * 60 * 24 * 365) = 69年
工作机器id（10bit）：也被叫做workId，这个可以灵活配置，机房或者机器号组合都可以。
序列号部分（12bit），自增值支持同一毫秒内同一个节点可以生成4096个ID
根据这个算法的逻辑，只需要将这个算法用Java语言实现出来，封装为一个工具方法，那么各个业务应用可以直接使用该工具方法来获取分布式ID，只需保证每个业务应用
有自己的工作机器id即可，而不需要单独去搭建一个获取分布式ID的应用
