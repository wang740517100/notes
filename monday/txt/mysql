--------------------  查询sql优化 --------------------------
1)把数据量大的表作为驱动表
3)用exists代替in的子查询
2)在查询多的表上建立索引(一般结果在20%左右):
- 在经常使用where条件的字段上建立索引、
- 在表关联的字段上建立索引
- 在经常使用order by 或 group by的字段建立索引
- 根据情况优先使用唯一索引, 单个索引区分度不大时使用联合索引
3)索引失效的情况
- 右模糊匹配时
- 联合索引使用了只使用了右边的索引
- 索引字段是int使用str查询时
- 索引参与运算或使用函数
- 数据量特别少只有几条(全表查询更快时)

--------------------  mysql server 组件 --------------------------
client -> server -> 存储层
client: 连接池
server: 连接器 --> 查询缓存 --> 解析器 -> 执行器
存储层: innodb、myisam

连接器:
1)由一个工作线程去从一个网络连接中读取SQL语句
解析器
2)SQL接口(SQL Interface)执行SQL语句
3)查询解析器(Parser)对SQL语句进行拆分解析
4)查询优化器选择最优的查询路径
执行器:
5)执行器根据执行计划调用存储引擎的接口

innodb存储引擎(更新操作示例):
1)执行器发送更新调用后, 引擎会先查看缓冲池里面有没有数据, 如果没有就从磁盘加载
2)对需要更新的数据加索引记录锁
3)将原值写入undo日志里面
4)先更新缓冲池里面数据(磁盘数据还未修改), 将更新后值命令写入Redo Log Buffer(放redo日志的)
5)提交事务时将redo日志写入磁盘文件(数据还未修改), 同时写binlog, 最后在redo日志写commit命令
innodb_flush_log_at_trx_commit: redo日志提交策略
- 0: 提交事务不会把redo log buffer里的数据刷入磁盘文件
- 1: 提交事务必须把redo log从内存刷入到磁盘文件, 一般选择这个保证数据强一致性
- 2: 提交事务把redo日志写入磁盘文件对应的os cache缓存里去, 可能1秒后才会把os cache里的数据写入到磁盘文件
ps: binlog日志也有对应的提交策略
6)将缓存池里的缓存页加入flush链表, 后台线程异步随机将缓冲池数据刷新到磁盘

redo log(重做日志): 属于InnoDB存储引擎特有的一个东西
binlog(归档日志): 属于mysql server自己的日志文件

------------------------ 客户端连接池调优 ----------------------------------------
1)使用 HikariCP, 其它(C3P0, DBCP2, Tomcat JDBC Pool)
2)简单原则: 核心连接数 = cpu核数 * 2, 不要空闲连接防止峰值带来抖动
3)根据实际情况去调整参数(核心连接，空闲连接，空闲连接超时时间等)
4)开启mybatis的二级缓存(sqlSession、mapper级别:多个SqlSession在同一个Mapper文件中共享的缓存)

-------------------- 缓冲池 -------------------------------------------
innodb的buffer pool(缓冲池):
每次读写都会经过缓冲池, 该值设置越大越好, 缓冲池也是以page为单位的。
innodb_buffer_pool_size: 总容量
innodb_buffer_pool_instance: 缓冲池个数(总容量不变，建议和cpu核数保持一致将热点打散)
ps: 一般机器内存的50%~60%左右。 eg: buffer pool大小就是20GB, 然后buffer pool数量是32个,
每个buffer pool的大小是640MB, 然后每个buffer pool包含5个128MB的chunk
- SHOW ENGINE INNODB STATUS

将磁盘上的数据读到缓存池时:
1)根据缓存hash表查看缓存池有没有该sql缓存页信息
1)从free链表里获取一个描述数据块, 获取到这个描述数据块对应的空闲缓存页
2)把磁盘上的数据页读取到对应的缓存页, 把相关的描述数据写入缓存页的描述数据块
3)把对应描述数据块从free链表里去除, 加入缓存hash表, 写入lru链表冷区域头部

buffer pool里的数据结构:
缓存页: 用来放磁盘数据页, 每个页上有元元素(描述信息: 所属的表空间、数据页的编号等)
free链表(双向链表、基础节点): 放置空闲缓存页信息, value信息就是缓存页元数据块
flush链表: 将缓冲池里更新后的脏叶放在链表上供后台线程更新磁盘数据时用
缓存hash表: 表空间号+数据页号作为一个key, 然后缓存页的地址作为value
LRU链表(冷热分离): 当缓存池缓存页不够时使用最近最少淘汰算法将缓存页刷到磁盘更新为空闲缓存页

LRU优化方案(冷热分离, 热数据移动)
1)innodb_old_blocks_time: 1000  #默认1000, 也就是1000毫秒, 一个数据页被加载到缓存页之后
  在1s之后才会被挪动到热数据区域的链表头部去
2)只有在热数据区域的后3/4部分的缓存页被访问了才会给移动到热数据区域头部
3)淘汰触发时机: 定时任务和加载时淘汰
ps: 全表扫描和预热时会将数据加载到lru链的冷数据区域头部, 在1s后访问才会挪动到热区域头部去

------------------------ mysql物理数据模型 ------------------------
段(segment) -> 区(extent) -> 页(page) -> 行(row)
1)extent是最小申请单位(一般申请4个), page是I/O操作的最小对象，row是data的最小单位
2)普通表默认每个page是16K, extent的固定大小时1M(64个page)
3)单个区上物理空间是连续的, 不同区不保证连续


row的数据结构: 变长字段的长度列表、NULL值列表、隐藏字段、存储信息
- 变长字段长度列表: 十六机制, 逆序排列
- null值列表: 二进制, 1说明是NULL, 0说明不是NULL, 逆序排列
- 数据头: 40bit(1/2位是预留位, 3是delete_mask, 4是min_rec_mask, 5-8是n_owned,
       9-22是heap_no, 22-24是record_type, 24-40是next_record)
- 隐藏字段: DB_ROW_ID(隐藏ID)、个DB_TRX_ID(当前事务ID)、DB_ROLL_PTR(undo日志版本号)
eg: 变长列表 null值列表 数据头 隐藏列 hello a a
eg: 0x05 000 0000000000000000000010000000000000011001 00000000094C 00000000032D EA000010078E hello a a 0x02 000

行溢出: 行数据超过了页大小, 这个时候实际上会在那一页里存储你这行数据, 然后在超长字段中仅仅包含一部分数据,
同时包含一个20个字节的指针, 指向了其他的一些数据页(溢出页), 那些数据页用链表串联起来存放超大字段里的数据

page的数据结构:
- 文件头: 38个字节
- 数据页头: 56个字节
- 最小记录和最大记录: 26个字节
- 多个数据行: 用来放行数据
- 空闲空间:
- 数据页目录: 放的是主键与数据的映射关系
- 文件尾部: 8个字节

tablespace的数据结构: 磁盘文件(.ibd), 组成是 组(extents) -> 区(extent)
一个数据区对应着连续的64个数据页, 每个数据页是16kb, 所以一个数据区是1mb, 然后256个数据区被划分为了一组,
对于表空间而言, 他的第一组数据区的第一个数据区的前3个数据页都是固定的,里面存放了一些描述性的数据:
- FSP_HDR: 存放了表空间和这一组数据区的一些属性
- IBUF_BITMAP: 存放的是这一组数据页的所有insert buffer的一些信息
- INODE: 存放了一些特殊的信息


磁盘随机读: 在表空间里加载数据页时采用的是磁盘随机读, 主要关注的性能指标是IOPS和响应延迟
磁盘顺序写: 在Buffer Pool的缓存页里更新了数据之后写一条redolog日志, 几乎跟内存随机读写的性能差不多
- IOPS: 底层的存储系统每秒可以执行多少次磁盘读写操作
- 响应延迟: 磁盘随机读响应时间


------------------------ mysql的redo日志和undo日志 ------------------------

redo日志结构: 表空间号+数据页号+数据页内偏移量+修改了几个字节的数据+实际修改数据

redo log block: 512字节, header有12字节, body有496字节, trailer有4字节
header组成:
- 包括4个字节的block no，就是块唯一编号；
- 2个字节的data length，就是block里写入了多少字节数据；
- 2个字节的first record group。
- 4个字节的checkpoint on

redo log buffer:
1)如果写入redo log buffer的日志已经占据了redo log buffer总容量的一半了(8MB)会把他们刷入到磁盘文件
2)一个事务提交的时候, 必须把他的那些redo log所在的redo log block都刷入到磁盘文件里去
3)后台线程定时刷新, 有一个后台线程每隔1秒就会把redo log buffer里的redo log block刷到磁盘文件里去
4)MySQL关闭的时候, redo log block都会刷入到磁盘里去


undo回滚日志不想写了......


------------------------ 事务和隔离级别 --------------------------
事务的四个特性: 原子性、 隔离性、 持久性、 一致性

脏写: 事务A改了行数据, 事务B也改了该行数据, 事务A回滚, 事务B提交, 事务B的数据也被回滚了
脏读: 事务A改了行数据, 事务B读了事务A修改后的数据, 事务A回滚, 事务B又读到不同数据
不可重复读: 事务A读行数据, 事务B修改了该行数据提交事务, 事务A再次读到事务B修改后的数据
幻读: 事务A读行数据, 事务B增加了行数据提交事务, 事务A再次读到事务B修改后的多条数据

SQL标准的四种隔离级别(默认是rr):
1)read uncommitted: 只支持快照读(snapshot read)
2)read committed: 解决了脏读, 使用mvcc实现
3)reapeatable read: 解决了重复读, 使用mvcc实现(防止的是快照读的幻读), mysql默认
4)serializable: 事务串行执行, 解决了幻读, 使用当前读(s锁实现，qps只有几十效率慢)
ps: MySQL的RR级别可以避免幻读发生, mvcc

-------------------- mvcc实现的rc和rr --------------------------
mvcc(多版本并发协议): undo log多版本链条 + ReadView机制
1)事务版本号: 每次事务开启会一个自增长的事务ID, 可以从事务ID判断事务的执行先后顺序
2)表的隐藏列:
- DB_TRX_ID: 记录操作该数据事务的事务ID
- DB_ROLL_PTR：指向上一个版本数据在undo log 里的位置指针
- DB_ROW_ID: 隐藏ID, 当创建表没有合适的索引作为聚簇索引时, 会用该隐藏ID创建聚簇索引
3)undo log: 记录数据变化的过程, 事务回滚时使用, MVCC快照读时使用
4)read view: 执行一个事务的时都会得到一个read_view
- trx_ids: 当前系统活跃(未提交)事务版本号集合。
- low_limit_id: 创建当前read view 时“当前系统最大事务版本号+1”。
- up_limit_id: 创建当前read view 时“系统正处于活跃事务最小版本号”
- creator_trx_id: 创建当前read view的事务版本号；

read view的匹配规则:
1)数据事务ID < up_limit_id 则显示
2)数据事务ID >= low_limit_id 则不显示
3)up_limit_id < 数据事务ID < low_limit_id 则与活跃事务集合 trx_ids 里匹配
- 如果事务ID不存在于 trx_ids 集合, 这种情况数据则可以显示
- 如果事务ID存在 trx_ids 集合且等于 creator_trx_id 也是可以显示的
- 如果事务ID既存在 trx_ids且不等于creator_trx_id 此数据不能显示
4)不满足 read view 条件时候, 从 undo log 里面获取数据


--------------------- 锁机制 ---------------------------------------
多个事务同时更新一行数据, 此时都会加锁然后都会排队等待, 必须一个事务执行完毕了提交
了释放了锁才能唤醒别的事务继续执行

快照读: rc和rr隔离级别支持, 使用mvcc实现
当前读: 使用 next-key lock(record lock && gap lock) 实现

mysql的查询默认是使用mvcc机制不用加锁的
- 加共享锁 select * from table lock in sharemode
- 加排它锁 select * from table for update
一般开发业务系统查询主动加共享锁的情况较为少见, 数据库的行锁是实用功能, 一般不会在数据库层面做复杂的
手动加锁操作, 反而会用基于redis/zookeeper的分布式锁来控制业务系统的锁逻辑

DDL语句(alter)是通过MySQL通用的Metadata Locks(元数据锁)实现的, 元数据锁与行锁是互斥的
InnoDB存储引擎的表锁: 排鸡肋基本不会用
- LOCK TABLES xxx READ: 这是加表级共享锁
- LOCK TABLES xxx WRITE: 这是加表级独占锁
- 意向共享锁: 读数据自动加
- 意向独占锁: 更新数据时会自动加
ps: 一般来讲，都是对同一行数据的更新操作加的行级独占锁是互斥, 跟读操作都是不互斥的,
读操作默认都是走mvcc机制读快照版本的！

--------------------------行锁: 排它锁和共享锁 -------------------
X 排它锁 和 S 共享锁

--------------------------表锁: 意向锁----------------------------
intention locks(意向锁): 行锁有一个问题，如果一个事务对一张表的某条数据进行加锁，这时如果有另外一个线程想要用
LOCK TABLES进行锁表，这时候数据库要怎么知道哪张表的哪条数据被加了锁，一条条数据去遍历是不可行的。InnoDB考虑到
这种情况，设计出另外一组锁，意向共享锁（IS）和意向排他锁(IX)。
IS(意向共享锁): 当一个事务要给一条数据加S锁的时候, 会先对数据所在的表先加上IS锁, 成功后才能在行上加上S锁
XS(意向排它锁): 当一个事务要给一条数据加X锁的时候, 会先对数据所在的表先加上IX锁, 成功后才能在行上加上X锁

设置IS: select ... lock in share mode
设置IX: select ... for update 

-------------------------- record locks 索引记录锁 --------------------------
会锁定索引的多条记录, 如果表没有指定索引, 那么Innodb会创建一个隐藏的聚簇索引, 然后锁定该索引。

--------------------------  gap locks 间隙锁 --------------------------
锁定索引记录之间的间隙, rr默认开启间隙锁, rc不支持间隙锁, 可以通过 innodb_locks_unsafe_for_binlog 关闭间隙锁。
间隙锁可以防止幻读，也是rr和rc最大的区别所在。比如普通索引b的值为[10, 15, 20, 30], 如果锁定值为20的行, 此时间隙锁
锁定区间为(15,20)和(20,30)

--------------------------  next-key locks --------------------------
record locks和gap locks的结合，包含了行锁和锁定行之前间隙的间隙锁


-------------------------- insert intention locks 插入意向锁 --------------------------
是一种间隙锁，在insert之前被设置。这个锁表示将要插入数据, 多个事务同时插入相同的索引间隙内不会冲突, 除非插入的是同
一个位置。假设索引列有两个值4和7, 两个不同的事务分别想要插入5和6, 在获得索引行上的X锁之前, 他们各自会使用插入意向锁
锁定4和7之间的间隙, 但是他们不会相互阻塞, 因为插入的是不同位置的行。

-------------------------- auto-inc locks 自增主键锁 --------------------------
是一个特殊的表级别(table-level)的锁, 当插入包含auto-increment属性列的表时会用到该锁。简单是说, 一个事务向表中插入
一条数据, 那么其他事务的插入操作就需要等待, 这样第一个获得锁的事务就能获得一个连续自增的主键值。

-------------------------- 索引 --------------------------

磁盘数据: 大量的数据页是按顺序一页一页存放的, 然后两两相邻的数据页之间会采用双向链表的格式互相引用

全表扫描: 没有索引只能全表扫描将数据页从头到尾加载进缓冲池中依次查询

页分裂: 新增数据时保证数据页按照主键大小依次排序

索引: 主键的索引实际上就是主键目录, 这个主键目录就是把每个数据页的页号和最小的主键值放在一起组成一个索引的目录

聚簇索引: B+树非叶子节点上都是索引页, 叶子节点上是数据页

普通索引/二级索引

索引下推(mysql5.6): 索引下推在非主键索引上的优化，可以有效减少回表的次数，大大提升了查询的效率。

-------------------------- 索引调优的三个工具 --------------------------
1) explain run your sql1

2)profile
set profiling=1;                  //打开分析
run your sql1;
show profiles;                    //查看sql1的语句分析
show profile for query 1;        //查看sql1的具体分析
show profile ALL for query 1;    //查看sql1相关的所有分析【主要看i/o与cpu,下边分析中有各项意义介绍】
set profiling=0;                  //关闭分析

3)optimizer_trace
show variables like '%optimizer_trace%';
set optimizer_trace='enabled=on,one_line=on';
run your sql1;
select * from information_schema.optimizer_trace\G;
set optimizer_trace='enabled=off,one_line=off';



-------------------------- mysql为什么要实现最左匹配原则 --------------------------
mysql创建复合索引的规则是首先会对复合索引的最左边的，也就是第一个name字段的数据进行排序，在第一个字段的排序基础上，
然后再对后面第二个的cid字段进行排序。其实就相当于实现了类似 order by name cid这样一种排序规则。

所以：第一个name字段是绝对有序的，而第二字段就是无序的了。所以通常情况下，直接使用第二个cid字段进行条件判断是用不到索引的，
当然，可能会出现上面的使用index类型的索引。这就是所谓的mysql为什么要强调最左前缀原则的原因。